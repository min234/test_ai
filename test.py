from phi.agent import Agent
from phi.model.openai import OpenAIChat
from phi.tools.shell import ShellTools
from phi.tools.file import FileTools
from dotenv import load_dotenv
import os
import json
import subprocess

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âš ï¸ `.env` íŒŒì¼ì— `OPENAI_API_KEY`ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

file_list_agent = Agent(
        name="File List Agent",
        model=OpenAIChat(id="gpt-4", api_key=OPENAI_API_KEY),
        tools=[FileTools()],    
        description="ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ ëª©ë¡ í™•ì¸",
        instructions=[
            "Always use the given absolute directory path.",
            "Do not navigate to parent or sibling directories.",
            "Return only files directly in the specified directory."
        ],
        show_tool_calls=True,
        markdown=True,
        debug_mode=True,
    )


language_detection_agent = Agent(
    name="Language Detection Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    description="ì–¸ì–´ íŒë³„",
    markdown=True,
    debug_mode=True,
)

language_detection_assistant_agent = Agent(
    name="Language Detection Assistant Agent",
    model=OpenAIChat(id="gpt-4", api_key=OPENAI_API_KEY),
    description="ê¸´ ì½”ë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” ì–¸ì–´ íŒë³„ ë³´ì¡° ì—ì´ì „íŠ¸",
    markdown=True,
    debug_mode=True,
)

language_detection_assistant_last_agent = Agent(
    name="Language Detection Assistant Agent",
    model=OpenAIChat(id="gpt-4", api_key=OPENAI_API_KEY),
    description="ê¸´ ì½”ë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” ì–¸ì–´ íŒë³„ ë³´ì¡° ì—ì´ì „íŠ¸",
    markdown=True,
    debug_mode=True,
)

test_runner_agent = Agent(
    name="Test Runner Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    tools=[ShellTools()],
    show_tool_calls=True,
    description="í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
    markdown=True,
    debug_mode=True,
)

error_analysis_agent = Agent(
    name="Error Analysis Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    description="ì˜¤ë¥˜ ë¶„ì„",
    markdown=True,
    debug_mode=True,
)

test_file_generator_agent = Agent(
    name="Test File Generator Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    tools=[FileTools()],
    description="í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±",
    markdown=True,
    debug_mode=True,
)

run_test_agent = Agent(
    name="Test Runner Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    tools=[FileTools()],
    description="ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
    markdown=True,
    debug_mode=True,
)



# âœ… 1. íŒŒì¼ ëª©ë¡ í™•ì¸

def list_all_files(directory: str):
    """
    ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    'node_modules', '__pycache__' í´ë” ë° íŠ¹ì • í™•ì¥ì íŒŒì¼ì€ ì œì™¸ë©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ ë””ë ‰í„°ë¦¬ '{directory}'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤... (node_modules, __pycache__ ì œì™¸)")

    if not os.path.exists(directory):
        raise ValueError(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
    if not os.path.isdir(directory):
        raise ValueError(f"âŒ ê²½ë¡œê°€ ë””ë ‰í„°ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {directory}")

    excluded_dirs = {'node_modules', '__pycache__','.pytest_cache','.env'}
    excluded_extensions = {'.pyc', '.pyo', '.log','.md','.TAG','.gitignore','.env'}

    all_files = []
    for root, dirs, files in os.walk(directory):
        # ì œì™¸í•  ë””ë ‰í† ë¦¬ ë¬´ì‹œ
        dirs[:] = [d for d in dirs if d not in excluded_dirs]

        # ì œì™¸í•  íŒŒì¼ í™•ì¥ì ë¬´ì‹œ
        for file in files:
            file_path = os.path.join(root, file)
            if not any(file_path.endswith(ext) for ext in excluded_extensions):
                all_files.append(file_path)

    print(f"âœ… {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (ì œì™¸ ë””ë ‰í† ë¦¬ ë° í™•ì¥ì ì ìš©)")
    return all_files

def split_code_into_chunks(content, chunk_size=1000):
    """
    ê¸´ ì½”ë“œë¥¼ ì§€ì •ëœ í¬ê¸°(chunk_size)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    ê°€ëŠ¥í•œ ê²½ìš° ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ì½”ë“œì˜ ë…¼ë¦¬ì  íë¦„ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    lines = content.splitlines()  # ì½”ë“œë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”
    chunks = []
    current_chunk = []

    current_length = 0
    for line in lines:
        line_length = len(line) + 1  # ì¤„ë°”ê¿ˆ ë¬¸ì í¬í•¨
        if current_length + line_length > chunk_size:
            # í˜„ì¬ ì²­í¬ê°€ ê°€ë“ ì°¼ìœ¼ë©´ ì €ì¥
            chunks.append("\n".join(current_chunk))
            current_chunk = []
            current_length = 0

        current_chunk.append(line)
        current_length += line_length

    # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if current_chunk:
        chunks.append("\n".join(current_chunk))

    return chunks

def detect_languages(file_paths):
    """
    íŒŒì¼ ëª©ë¡ì—ì„œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í…ŒìŠ¤íŠ¸ ì½”ë“œ ì¡´ì¬ ì—¬ë¶€ë¥¼ ìµœì¢… íŒë‹¨í•©ë‹ˆë‹¤.
    """
    print("ğŸŒ Language Agentì™€ ë³´ì¡° ì—ì´ì „íŠ¸ê°€ íŒŒì¼ ì–¸ì–´ì™€ í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨ ì—¬ë¶€ë¥¼ ê°ì§€í•©ë‹ˆë‹¤...")

    if not file_paths:
        print("âŒ íŒŒì¼ ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {}

    detected_languages = {}

    for file_path in file_paths:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ì´ˆê¸°í™”
            language_results = []
            has_test_code_results = []
            chunk_results = []

            # ì½”ë“œê°€ 1000ìë³´ë‹¤ ê¸´ ê²½ìš° ë³´ì¡° ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í¬ë¡œ ì²˜ë¦¬
            if len(content) > 1000:
                chunks = split_code_into_chunks(content)

                for chunk in chunks:
                    response = language_detection_assistant_agent.run(
                        f"""ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í•´ë‹¹ ì–¸ì–´ì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ íŒ¨í„´ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:
                        - ì–¸ì–´: Python, JavaScript, TypeScript, Java ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
                        - í…ŒìŠ¤íŠ¸ ì½”ë“œ íŒ¨í„´: ì•„ë˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.
                        - Python: pytest, unittest ('def test_', '@pytest', 'assert').
                        - JavaScript/TypeScript: Jest, Mocha, Jasmine ('describe', 'it', 'test', 'expect').
                        - Java: JUnit ('@Test', 'Assert', 'public void test').

                        ì½”ë“œ:
                        {chunk}
                        """,
                        stream=False
                    )

                    if hasattr(response, 'content') and response.content:
                        language = response.content.strip()
                        language_results.append(language)
                        has_test_code = any(
                            keyword in chunk for keyword in [
                                'def test_', '@pytest', 'assert', 
                                'describe', 'it', 'test', '@Test', 
                                'Assert', 'public void test'
                            ]
                        )
                        has_test_code_results.append(has_test_code)
                        chunk_results.append({"chunk": chunk, "response": response.content.strip()})
                    else:
                        language_results.append("ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨")
                        has_test_code_results.append(False)

            # ì „ì²´ ì½”ë“œì— ëŒ€í•´ì„œë„ ë¶„ì„
            response = language_detection_agent.run(
                f"""ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í•´ë‹¹ ì–¸ì–´ì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ íŒ¨í„´ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:
                - ì–¸ì–´: Python, JavaScript, TypeScript, Java ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
                - í…ŒìŠ¤íŠ¸ ì½”ë“œ íŒ¨í„´: ì•„ë˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.
                - Python: pytest, unittest ('def test_', '@pytest', 'assert').
                - JavaScript/TypeScript: Jest, Mocha, Jasmine ('describe', 'it', 'test', 'expect').
                - Java: JUnit ('@Test', 'Assert', 'public void test').

                ì½”ë“œ:
                {content}
                """,
                stream=False
            )

            if hasattr(response, 'content') and response.content:
                language_results.append(response.content.strip())
                has_test_code = any(
                    keyword in content for keyword in [
                        'def test_', '@pytest', 'assert', 
                        'describe', 'it', 'test', '@Test', 
                        'Assert', 'public void test'
                    ]
                )
                has_test_code_results.append(has_test_code)
            else:
                language_results.append("ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨")
                has_test_code_results.append(False)

            # ìµœì¢… íŒë‹¨: í†µí•©ëœ ë°ì´í„°ë¡œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            final_response = language_detection_assistant_last_agent.run(
                f"""ë‹¤ìŒì€ íŒŒì¼ì˜ ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤:
                - ì²­í¬ ë¶„ì„ ê²°ê³¼: {chunk_results}
                - ì „ì²´ ì½”ë“œ ë¶„ì„ ê²°ê³¼: {response.content.strip() if hasattr(response, 'content') else "ë¶„ì„ ì‹¤íŒ¨"}
                - ì²­í¬ë³„ í…ŒìŠ¤íŠ¸ ì½”ë“œ í”Œë˜ê·¸: {has_test_code_results}

                ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì´ íŒŒì¼ì´ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ ìµœì¢… íŒë‹¨í•´ì£¼ì„¸ìš”.
                - ë°˜í™˜: 'True' ë˜ëŠ” 'False'
                """,
                stream=False
            )

            # ìµœì¢… íŒë‹¨ ê²°ê³¼ ë°˜ì˜
            if hasattr(final_response, 'content') and final_response.content.strip().lower() in ["true", "false"]:
                has_test_code = final_response.content.strip().lower() == "true"

            # ì–¸ì–´ ìµœë¹ˆê°’ ê³„ì‚°
            language_count = {}
            for lang in language_results:
                language_count[lang] = language_count.get(lang, 0) + 1
            final_language = max(language_count, key=language_count.get)

            # ê²°ê³¼ ì €ì¥
            detected_languages[file_path] = {
                "language": final_language,
                "has_test_code": has_test_code
            }

            print(f"âœ… {file_path}: ì–¸ì–´: {final_language}, í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨ ì—¬ë¶€: {has_test_code}")

        except Exception as e:
            print(f"âŒ {file_path}: ì˜¤ë¥˜ ë°œìƒ - {e}")

    print(f"âœ… Language Agentê°€ {len(detected_languages)}ê°œì˜ íŒŒì¼ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")
    return detected_languages


def check_and_generate_test_files(target_files):
    """
    í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ì†ŒìŠ¤ íŒŒì¼ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ì†ŒìŠ¤ ì½”ë“œ ìì²´ì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.
    """
    generated_tests = []
    existing_tests = []

    for source_file_path, metadata in target_files.items():
        language = metadata.get('language')
        has_test_code = metadata.get('has_test_code', False)

        if not language:
            print(f"âš ï¸ ì–¸ì–´ê°€ ê°ì§€ë˜ì§€ ì•Šì€ íŒŒì¼: {source_file_path}. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            continue

        if has_test_code:
            print(f"âœ… ì†ŒìŠ¤ ì½”ë“œì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {source_file_path}")
            existing_tests.append((source_file_path, language))
            continue

        file_dir = os.path.dirname(source_file_path)
        file_name, file_ext = os.path.splitext(os.path.basename(source_file_path))
        test_file_path = os.path.join(file_dir, f"{file_name}.test{file_ext}")

        if os.path.exists(test_file_path):
            print(f"âœ… ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë°œê²¬: {test_file_path}")
            existing_tests.append((test_file_path, language))
        else:
            generated_file = generate_test_file_from_code(source_file_path, test_file_path)
            if generated_file:
                generated_tests.append((test_file_path, language))

    print(f"âœ… ì´ {len(generated_tests)}ê°œì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"âœ… ì´ {len(existing_tests)}ê°œì˜ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return generated_tests, existing_tests



def generate_test_file_from_code(source_file_path, test_file_path):
    """
    ì£¼ì–´ì§„ ì›ë³¸ ì½”ë“œ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ AIê°€ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ {source_file_path} íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    try:
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        source_file_path = os.path.abspath(source_file_path)
        test_file_path = os.path.abspath(test_file_path)
        
        print(f"ğŸ“‚ ì›ë³¸ ì½”ë“œ íŒŒì¼: {source_file_path}")
        print(f"ğŸ’¾ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {test_file_path}")
        
        # ì›ë³¸ ì½”ë“œ ì½ê¸°
        if not os.path.exists(source_file_path):
            print(f"âŒ ì›ë³¸ ì½”ë“œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_file_path}")
            return None
        
        with open(source_file_path, 'r', encoding='utf-8') as f:
            code_content = f.read()
        print("âœ… ì›ë³¸ ì½”ë“œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
        
        # AIì— í…ŒìŠ¤íŠ¸ ì½”ë“œ ìš”ì²­
        print("ğŸ¤– AIì—ê²Œ í…ŒìŠ¤íŠ¸ ì½”ë“œ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
    
        response = test_file_generator_agent.run(
            f"""ë‹¤ìŒ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            - ì–¸ì–´: Python, JavaScript, TypeScript, Java ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.
            - í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬:
              - Python: pytest
              - JavaScript/TypeScript: Jest
              - Java: JUnit
            - ë°˜í™˜ëœ ë‚´ìš©ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•©ë‹ˆë‹¤.
            -ìˆœìˆ˜ ì½”ë“œë¡œë§Œ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤.
            ì½”ë“œ:
            {code_content[:1000]}  # ì¼ë¶€ ì½”ë“œë§Œ ì „ë‹¬
            """,
            stream=False
        )
        # RunResponse ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
        response_content = response.content if hasattr(response, 'content') else str(response)

        print(f"ğŸ” AI ì‘ë‹µ:\n{response_content}")
        os.makedirs(os.path.dirname(test_file_path), exist_ok=True)
        with open(test_file_path, 'w', encoding='utf-8') as f:
            f.write(response_content.strip())

        if not response_content or "import pytest" not in response_content.replace("\n", "").replace(" ", ""):
            print("âŒ AIê°€ ì˜¬ë°”ë¥¸ pytest ì½”ë“œë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì“°ê¸°
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {test_file_path}")

        # ì €ì¥ëœ íŒŒì¼ ë‚´ìš© í™•ì¸
        with open(test_file_path, 'r', encoding='utf-8') as f:
            saved_content = f.read()
            print("ğŸ“ ì €ì¥ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©:")
            print(saved_content)
        print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {test_file_path}")
        return test_file_path
    
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# âœ… 7. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
def run_test_file(test_file, directory, language):
    """
    í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ Test Runner Agentê°€ {language} í…ŒìŠ¤íŠ¸ íŒŒì¼ {test_file}ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")

    # ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ë§¤í•‘
    command = {
        "Python": f"pytest -v {test_file}",
        "JavaScript": "npm test",
        "TypeScript": "npm test",
        "Java": "mvn test"
    }.get(language)

    if not command:
        print(f"âš ï¸ {language}ëŠ” ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.")
        return {"stderr": f"Unsupported language: {language}"}

    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        result = subprocess.run(
            command,
            shell=True,
            text=True,
            capture_output=True,
            cwd=directory
        )
        return {"stdout": result.stdout, "stderr": result.stderr}
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"stderr": str(e)}

# âœ… ì—ì´ì „íŠ¸ í™œìš© ë¡œì§

def analyze_and_run_test(file_path, language):
    """
    íŒŒì¼ì„ ë¶„ì„í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” íŒŒì¼ ë¶„ì„ ì¤‘: {file_path}")

    # í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        return {"error": "File not found"}

    # íŒŒì¼ ê²½ë¡œì™€ ë””ë ‰í† ë¦¬ ë¶„ë¦¬
    directory = os.path.dirname(file_path)
    file_name = os.path.basename(file_path)

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = run_test_file(file_name, directory, language)

    # ê²°ê³¼ ì¶œë ¥ ë° ë¶„ì„
    stdout = result.get("stdout", "")
    stderr = result.get("stderr", "")

    if stderr:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {stderr}")
    else:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼:\n{stdout}")

    return result


def analyze_errors(error_logs):
    if not error_logs.strip():
        print("âœ… ì˜¤ë¥˜ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "No errors detected"
    
    print("ğŸ Error Analysis Agentê°€ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    response = error_analysis_agent.run(
        f"ë‹¤ìŒ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ì›ì¸ê³¼ í•´ê²°ì±…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{error_logs}",
        stream=False
    )

    return response.content.strip() if hasattr(response, 'content') else "ë¶„ì„ ì‹¤íŒ¨"


def full_project_analysis(directory):
    """
    ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ í™•ì¸, í…ŒìŠ¤íŠ¸, ë¶„ì„í•©ë‹ˆë‹¤.
    """
    print("\nğŸ“ **1ë‹¨ê³„: íŒŒì¼ ëª©ë¡ í™•ì¸**")
    file_paths = list_all_files(directory)

    if not file_paths:
        print("âŒ íŒŒì¼ ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print("\nğŸŒ **2ë‹¨ê³„: ì–¸ì–´ íŒë³„**")
    detected_languages = detect_languages(file_paths)

    if not detected_languages:
        print("âŒ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print("\nğŸ› ï¸ **3ë‹¨ê³„: í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸ ë° ìƒì„±**")
    generated_tests, existing_tests = check_and_generate_test_files(detected_languages)

    if not generated_tests and not existing_tests:
        print("âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ê³ , ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ë„ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print("\nğŸš€ **4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì˜¤ë¥˜ ë¶„ì„**")
    error_logs = ""
    test_results = {}

    # âœ… ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
    for test_file, language in existing_tests:
        print(f"\nğŸš€ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {test_file} ({language})")
        results = run_test_file(test_file, directory, language)
        test_results[test_file] = {
            "stdout": results.get("stdout", ""),
            "stderr": results.get("stderr", "")
        }
        error_logs += results.get("stderr", "")

    # âœ… ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
    for test_file, language in generated_tests:
        print(f"\nğŸš€ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {test_file} ({language})")
        results = run_test_file(test_file, directory, language)
        test_results[test_file] = {
            "stdout": results.get("stdout", ""),
            "stderr": results.get("stderr", "")
        }
        error_logs += results.get("stderr", "")

    print("\nğŸ **5ë‹¨ê³„: ì˜¤ë¥˜ ë¶„ì„**")
    error_analysis = analyze_errors(error_logs)

    print("\nğŸ¯ **ìµœì¢… ë¦¬í¬íŠ¸:**")
    report = {
        "file_count": len(file_paths),
        "detected_languages": detected_languages,
        "generated_tests": [test[0] for test in generated_tests],
        "existing_tests": [test[0] for test in existing_tests],
        "test_results": test_results,
        "error_analysis": error_analysis
    }
    print(json.dumps(report, indent=2, ensure_ascii=False))
    return report


# âœ… 9. ì‹¤í–‰
if __name__ == '__main__':
    directory = input("ğŸ“ ë¶„ì„ ë° í…ŒìŠ¤íŠ¸í•  ë¡œì»¬ í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    results = full_project_analysis(directory)
    print("\nğŸ¯ **ìµœì¢… ë¦¬í¬íŠ¸:**")
    print(json.dumps(results, indent=2, ensure_ascii=False))
