from phi.agent import Agent
from phi.model.openai import OpenAIChat
from phi.tools.shell import ShellTools
from phi.tools.file import FileTools
from dotenv import load_dotenv
import os
import json
import subprocess

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âš ï¸ `.env` íŒŒì¼ì— `OPENAI_API_KEY`ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

file_list_agent = Agent(
        name="File List Agent",
        model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
        tools=[FileTools()],
        description="ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ ëª©ë¡ í™•ì¸",
        instructions=[
            "Always use the given absolute directory path.",
            "Do not navigate to parent or sibling directories.",
            "Return only files directly in the specified directory."
        ],
        show_tool_calls=True,
        markdown=True,
        debug_mode=True,
    )


language_detection_agent = Agent(
    name="Language Detection Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    description="ì–¸ì–´ íŒë³„",
    markdown=True,
    debug_mode=True,
)

test_runner_agent = Agent(
    name="Test Runner Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    tools=[ShellTools()],
    show_tool_calls=True,
    description="í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
    markdown=True,
    debug_mode=True,
)

error_analysis_agent = Agent(
    name="Error Analysis Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    description="ì˜¤ë¥˜ ë¶„ì„",
    markdown=True,
    debug_mode=True,
)

test_file_generator_agent = Agent(
    name="Test File Generator Agent",
    model=OpenAIChat(id="gpt-4o", api_key=OPENAI_API_KEY),
    tools=[FileTools()],
    description="í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±",
    markdown=True,
    debug_mode=True,
)

# âœ… 1. íŒŒì¼ ëª©ë¡ í™•ì¸
def list_all_files(directory: str):
    """
    ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    'node_modules' í´ë”ëŠ” ì œì™¸ë©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ ë””ë ‰í„°ë¦¬ '{directory}'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤... (node_modules ì œì™¸)")

    if not os.path.exists(directory):
        raise ValueError(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
    if not os.path.isdir(directory):
        raise ValueError(f"âŒ ê²½ë¡œê°€ ë””ë ‰í„°ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {directory}")

    all_files = []
    for root, dirs, files in os.walk(directory):
        # `node_modules` í´ë”ëŠ” ë¬´ì‹œ
        if 'node_modules' in dirs:
            print(f"âš ï¸ 'node_modules' í´ë” ë¬´ì‹œ: {os.path.join(root, 'node_modules')}")
            dirs.remove('node_modules')
        
        for file in files:
            file_path = os.path.join(root, file)
            all_files.append(file_path)

    print(f"âœ… {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (node_modules ì œì™¸)")
    return all_files

def detect_languages(file_paths):
    """
    íŒŒì¼ ëª©ë¡ì—ì„œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í…ŒìŠ¤íŠ¸ ì½”ë“œ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    print("ğŸŒ Language Agentê°€ íŒŒì¼ ì–¸ì–´ì™€ í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨ ì—¬ë¶€ë¥¼ ê°ì§€í•©ë‹ˆë‹¤...")

    if not file_paths:
        print("âŒ íŒŒì¼ ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {}

    detected_languages = {}

    for file_path in file_paths:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            response = language_detection_agent.run(
                f"ë‹¤ìŒ ì½”ë“œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í…ŒìŠ¤íŠ¸ ì½”ë“œ(ì˜ˆ: 'test', 'describe', 'it', 'unittest', 'pytest')ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:\n\nì½”ë“œ:\n{content[:1000]}",
                stream=False
            )

            if hasattr(response, 'content') and response.content:
                language = response.content.strip()
                has_test_code = any(keyword in content for keyword in ['test', 'describe', 'it', 'unittest', 'pytest'])
                
                detected_languages[file_path] = {
                    'language': language,
                    'has_test_code': has_test_code
                }
                print(f"âœ… {file_path}: {language}, í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨: {has_test_code}")
            else:
                print(f"âŒ {file_path}: ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨")

        except Exception as e:
            print(f"âŒ {file_path}: ì˜¤ë¥˜ ë°œìƒ - {e}")

    print(f"âœ… Language Agentê°€ {len(detected_languages)}ê°œì˜ íŒŒì¼ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")
    return detected_languages


def check_and_generate_test_files(target_files):
    """
    í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ì†ŒìŠ¤ íŒŒì¼ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ì†ŒìŠ¤ ì½”ë“œ ìì²´ì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.
    """
    generated_tests = []
    existing_tests = []

    for source_file_path, metadata in target_files.items():
        language = metadata.get('language')
        has_test_code = metadata.get('has_test_code', False)

        if not language:
            print(f"âš ï¸ ì–¸ì–´ê°€ ê°ì§€ë˜ì§€ ì•Šì€ íŒŒì¼: {source_file_path}. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            continue

        # âœ… ì†ŒìŠ¤ ì½”ë“œì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ìˆëŠ” ê²½ìš° ìŠ¤í‚µ
        if has_test_code:
            print(f"âœ… ì†ŒìŠ¤ ì½”ë“œì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {source_file_path}")
            existing_tests.append((source_file_path, language))
            continue

        # âœ… ê°™ì€ ê²½ë¡œì— í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
        file_dir = os.path.dirname(source_file_path)
        file_name, file_ext = os.path.splitext(os.path.basename(source_file_path))
        test_file_path = os.path.join(file_dir, f"{file_name}.test{file_ext}")

        if os.path.exists(test_file_path):
            print(f"âœ… ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë°œê²¬: {test_file_path}")
            existing_tests.append((test_file_path, language))
        else:
            generated_file = generate_test_file_from_code(source_file_path, test_file_path)
            if generated_file:
                generated_tests.append((test_file_path, language))

    print(f"âœ… ì´ {len(generated_tests)}ê°œì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"âœ… ì´ {len(existing_tests)}ê°œì˜ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return generated_tests, existing_tests



def generate_test_file_from_code(source_file_path, test_file_path):
    """
    ì£¼ì–´ì§„ ì›ë³¸ ì½”ë“œ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ AIê°€ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ {source_file_path} íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    try:
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        source_file_path = os.path.abspath(source_file_path)
        test_file_path = os.path.abspath(test_file_path)
        
        print(f"ğŸ“‚ ì›ë³¸ ì½”ë“œ íŒŒì¼: {source_file_path}")
        print(f"ğŸ’¾ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {test_file_path}")
        
        # ì›ë³¸ ì½”ë“œ ì½ê¸°
        if not os.path.exists(source_file_path):
            print(f"âŒ ì›ë³¸ ì½”ë“œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_file_path}")
            return None
        
        with open(source_file_path, 'r', encoding='utf-8') as f:
            code_content = f.read()
        print("âœ… ì›ë³¸ ì½”ë“œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
        
        # AIì— í…ŒìŠ¤íŠ¸ ì½”ë“œ ìš”ì²­
        print("ğŸ¤– AIì—ê²Œ í…ŒìŠ¤íŠ¸ ì½”ë“œ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
    
        response = test_file_generator_agent.run(
            f"""ë‹¤ìŒ Python ì½”ë“œë¥¼ ìœ„í•œ pytest í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.
            - ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜í•œ Python ì½”ë“œë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
            - ë°˜í™˜ëœ ë‚´ìš©ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•©ë‹ˆë‹¤.
            
            ì½”ë“œ:
            {code_content[:1000]}
            """,
            stream=False
        )
        # RunResponse ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
        response_content = response.content if hasattr(response, 'content') else str(response)

        print(f"ğŸ” AI ì‘ë‹µ:\n{response_content}")
        os.makedirs(os.path.dirname(test_file_path), exist_ok=True)
        with open(test_file_path, 'w', encoding='utf-8') as f:
            f.write(response_content.strip())

        if not response_content or "import pytest" not in response_content.replace("\n", "").replace(" ", ""):
            print("âŒ AIê°€ ì˜¬ë°”ë¥¸ pytest ì½”ë“œë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì“°ê¸°
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {test_file_path}")

        # ì €ì¥ëœ íŒŒì¼ ë‚´ìš© í™•ì¸
        with open(test_file_path, 'r', encoding='utf-8') as f:
            saved_content = f.read()
            print("ğŸ“ ì €ì¥ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©:")
            print(saved_content)
        print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {test_file_path}")
        return test_file_path
    
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# âœ… 7. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
def run_test_file(test_file, directory, language):
    """
    í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ Test Runner Agentê°€ {language} í…ŒìŠ¤íŠ¸ íŒŒì¼ {test_file}ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")

    command = {
        "Python": f"pytest {test_file}",
        "JavaScript": "npm test",
        "TypeScript": "npm test",
        "Java": "mvn test"
    }.get(language)

    if not command:
        print(f"âš ï¸ {language}ëŠ” ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.")
        return {"stderr": f"Unsupported language: {language}"}

    result = subprocess.run(
        command,
        shell=True,
        text=True,
        capture_output=True,
        cwd=directory
    )
    return {"stdout": result.stdout, "stderr": result.stderr}


def analyze_errors(error_logs):
    if not error_logs.strip():
        print("âœ… ì˜¤ë¥˜ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "No errors detected"
    
    print("ğŸ Error Analysis Agentê°€ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    response = error_analysis_agent.run(
        f"ë‹¤ìŒ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ì›ì¸ê³¼ í•´ê²°ì±…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{error_logs}",
        stream=False
    )

    return response.content.strip() if hasattr(response, 'content') else "ë¶„ì„ ì‹¤íŒ¨"


def full_project_analysis(directory):
    """
    ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ í™•ì¸, í…ŒìŠ¤íŠ¸, ë¶„ì„í•©ë‹ˆë‹¤.
    """
    print("\nğŸ“ **1ë‹¨ê³„: íŒŒì¼ ëª©ë¡ í™•ì¸**")
    file_paths = list_all_files(directory)
    
    if not file_paths:
        print("âŒ íŒŒì¼ ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print("\nğŸŒ **2ë‹¨ê³„: ì–¸ì–´ íŒë³„**")
    detected_languages = detect_languages(file_paths)
    
    if not detected_languages:
        print("âŒ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print("\nğŸ› ï¸ **3ë‹¨ê³„: í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸ ë° ìƒì„±**")
    generated_tests, existing_tests = check_and_generate_test_files(detected_languages)
    
    if not generated_tests and not existing_tests:
        print("âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ê³ , ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ë„ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print("\nğŸš€ **4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì˜¤ë¥˜ ë¶„ì„**")
    error_logs = ""
    test_results = {}
    
    # âœ… ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
    for test_file, language in existing_tests:
        print(f"\nğŸš€ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {test_file} ({language})")
        results = run_test_file(test_file, directory, language)
        test_results[test_file] = {
            "stdout": results.get("stdout", ""),
            "stderr": results.get("stderr", "")
        }
        error_logs += results.get("stderr", "")
    
    # âœ… ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
    for test_file, language in generated_tests:
        print(f"\nğŸš€ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {test_file} ({language})")
        results = run_test_file(test_file, directory, language)
        test_results[test_file] = {
            "stdout": results.get("stdout", ""),
            "stderr": results.get("stderr", "")
        }
        error_logs += results.get("stderr", "")
    
    print("\nğŸ **5ë‹¨ê³„: ì˜¤ë¥˜ ë¶„ì„**")
    error_analysis = analyze_errors(error_logs)
    
    print("\nğŸ¯ **ìµœì¢… ë¦¬í¬íŠ¸:**")
    report = {
        "file_count": len(file_paths),
        "detected_languages": detected_languages,
        "generated_tests": [test[0] for test in generated_tests],
        "existing_tests": [test[0] for test in existing_tests],
        "test_results": test_results,
        "error_analysis": error_analysis
    }
    print(json.dumps(report, indent=2, ensure_ascii=False))
    return report



# âœ… 9. ì‹¤í–‰
if __name__ == '__main__':
    directory = input("ğŸ“ ë¶„ì„ ë° í…ŒìŠ¤íŠ¸í•  ë¡œì»¬ í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    results = full_project_analysis(directory)
    print("\nğŸ¯ **ìµœì¢… ë¦¬í¬íŠ¸:**")
    print(json.dumps(results, indent=2, ensure_ascii=False))
